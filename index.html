---
layout: page
title: Lohith Konathala
---

<div style="text-align: center; margin-bottom: 40px;">
  <img src="/assets/img/profile_picture_1.JPEG" alt="Lohith Konathala" style="border-radius: 50%; width: 200px; height: 200px; object-fit: cover;">
</div>

<h2>About Me</h2>
<p>I am a PhD student at Imperial College London researching Financial Machine Learning in the Intelligent Systems & Networks Group, supervised by Dr Giunchiglia. My research focuses on developing architecture-agnostic neurosymbolic layers for knowledge-constrained structured output prediction, with applications to asset allocation and ETF construction.</p>

<p>Previously, I completed my BA and MEng in Information & Computer Engineering at the University of Cambridge and worked as a Machine Learning Researcher at Neuphonic, where I researched stability and robustness for Speech-Language Models.</p>

<h2>Research Interests</h2>
<ul>
  <li>Neurosymbolic AI and knowledge-constrained prediction</li>
  <li>Financial machine learning and portfolio optimization</li>
</ul>

<h2>Education</h2>

<p><strong>PhD in Financial Machine Learning</strong><br>
Imperial College London (2025 â€“ 2028)<br>
<em>Supervisor: Dr Giunchiglia, Intelligent Systems & Networks Group</em></p>

<p><strong>BA, MEng in Information & Computer Engineering</strong><br>
University of Cambridge (2020 â€“ 2024)<br>
<em>Grade: Distinction (Top 20%)</em><br>
Relevant Courses: Deep Learning & Structured Data, Computational Statistics, Statistical Inference, Information Theory, Advanced Algorithms & Data Structures</p>

<h2>Experience</h2>

<p><strong>Machine Learning Researcher</strong><br>
Neuphonic, London, UK (Nov 2024 â€“ Sep 2025)</p>
<ul>
  <li>Researched stability and robustness for Speech-Language Models with experience implementing classifier-free guidance, model-merging and direct-preference optimisation (DPO). Presented research on DPO for Speech-Language Models at the UK & Ireland Speech Workshop, 2025.</li>
  <li>Led research on Speech-Language Model compression via embedding matrix pruning and multi-stage supervised fine-tuning on proprietary data. Open-sourced on HuggingFace as NeuTTS Air.</li>
  <li>Contributed to research on Finite Scalar Quantization (FSQ) Audio Codecs by co-supervising an interpretability study on acoustic and semantic feature representations, and analysing perturbation robustness of FSQ codes for channel-transmission (ICASSP 2026 submission).</li>
</ul>

<h2>Selected Publications</h2>

<p><strong>Challenges of Direct Preference Optimisation in Speech-Language Models</strong> (Jun 2025)<br>
Lohith Konathala, Rachel Beeson, Jiameng Gao<br>
<em>UK & Ireland Speech Workshop 2025</em></p>

<p><strong>FSQ Enables Transmission-Robust Neural Audio Compression at Low Bit-Rates</strong> (Sep 2025)<br>
Harry Julian, Rachel Beeson, Lohith Konathala, Johanna Ulin, Jiameng Gao<br>
<em>arXiv 2509.09550, under review for ICASSP 2026</em></p>

<h2>Open Source Contributions</h2>

<p><strong>NeuTTS Air</strong><br>
700M paramter Speech-Language Model for on-device TTS with instant voice cloning<br>
<a href="https://huggingface.co/neuphonic/neutts-air">ðŸ¤— HuggingFace</a></p>

<p><strong>NeuCodec</strong><br>
A lightweight neural codec using finite-scalar quantisation that encodes audio at 0.8 kbps<br>
<a href="https://huggingface.co/neuphonic/neucodec">ðŸ¤— HuggingFace</a></p>
